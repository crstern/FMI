{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "from sklearn.metrics import mean_squared_error, classification_report\n",
    "from scipy.io import wavfile\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import noisereduce as nr\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory for source file, verify if we have collected all the necessary data\n",
    "data_dir ='./ml-fmi-23-2020'\n",
    "audio_files_train = glob(data_dir + '/train/train/*.wav')\n",
    "audio_files_validation = glob(data_dir + '/validation/validation/*.wav')\n",
    "audio_files_test = glob(data_dir + '/test/test/*.wav')\n",
    "\n",
    "count_labels_mask_train, count_labels_mask_validation = 0, 0\n",
    "\n",
    "train_labels = []\n",
    "try:\n",
    "    train_data = open(data_dir + '/train.txt', \"r\")\n",
    "    for line in train_data:\n",
    "        filename, label = line.split(\",\")\n",
    "        index_file, extension = filename.split(\".\")\n",
    "        label = int(label[0])\n",
    "        \n",
    "        if label == 1: # we want to see how data is distributed\n",
    "            count_labels_mask_train += 1\n",
    "        \n",
    "        train_labels.append([index_file, label])\n",
    "except OSError as err:\n",
    "    print(\"OS error: {}\".format(err))\n",
    "except:\n",
    "    print(\"Unexpected error: \", sys.exc_info()[0])\n",
    "finally:\n",
    "    train_data.close()\n",
    "\n",
    "train_labels.sort(key = lambda t:t[0])\n",
    "\n",
    "\n",
    "validation_labels = []\n",
    "try:\n",
    "    validation_data = open(data_dir + '/validation.txt', \"r\")\n",
    "    for line in validation_data:\n",
    "        filename, label = line.split(\",\")\n",
    "        index_file, extension = filename.split(\".\")\n",
    "        label = int(label[0])\n",
    "        \n",
    "        if label == 1:\n",
    "            count_labels_mask_validation += 1\n",
    "        \n",
    "        validation_labels.append([index_file, label])\n",
    "except OSError as err:\n",
    "    print(\"OS error: {}\".format(err))\n",
    "except:\n",
    "    print(\"Unexpected error: \", sys.exc_info()[0])\n",
    "finally:\n",
    "    validation_data.close()\n",
    "\n",
    "validation_labels.sort(key = lambda t:t[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp; First step consist of visualizing the data, in order to identify audio properties that need preprocessing to ensure consistency across the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train files: 8000\n",
      "Number of train files labeled with 1: 4076\n",
      "Number of validation files: 1000\n",
      "Number of validation files labeled with 1: 528\n"
     ]
    }
   ],
   "source": [
    "# Number of audio files: training + validation\n",
    "print(\"Number of train files:\", len(audio_files_train))\n",
    "print(\"Number of train files labeled with 1:\", count_labels_mask_train)\n",
    "print(\"Number of validation files:\", len(audio_files_validation))\n",
    "print(\"Number of validation files labeled with 1:\", count_labels_mask_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ml-fmi-23-2020/train/train\\100043.wav\n",
      "samplerate: 16000 Hz\n",
      "channels: 1\n",
      "duration: 16000 samples\n",
      "format: WAV (Microsoft) [WAV]\n",
      "subtype: Signed 16 bit PCM [PCM_16]\n"
     ]
    }
   ],
   "source": [
    "#Extract some basic info about the file\n",
    "info = sf.info(audio_files_train[42])\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_mute_sound(audio, sample_rate, threshold):\n",
    "    audio = pd.Series(audio)\n",
    "    audio = audio.apply(np.abs)\n",
    "    audio = audio.rolling(window=int(sample_rate/32), min_periods=1, center=True)\n",
    "    audio = audio.mean()\n",
    "    \n",
    "    envelope = []\n",
    "    for audio_window in audio:\n",
    "        if audio_window > threshold:\n",
    "            envelope.append(True)\n",
    "        else:\n",
    "            envelope.append(False)\n",
    "            \n",
    "    return envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_noise(audio):\n",
    "    audio_noise_reduced = nr.reduce_noise(audio_clip = audio, noise_clip = audio, prop_decrease=0.28, verbose=False, pad_clipping = True)\n",
    "    return audio_noise_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp; Extracting features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_files, index_audio_file):\n",
    "    audio, sample_rate = librosa.load(audio_files[index_audio_file]) #it returns an audio time series and the sampling rate\n",
    "    \n",
    "    audio = reduce_noise(audio)\n",
    "    \n",
    "    mask = clean_mute_sound(audio, sample_rate, 0.0041)\n",
    "    audio = audio[mask]\n",
    "    \n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=80)\n",
    "    mfcc_scaled = np.mean(mfccs.T, axis = 0)\n",
    "    \n",
    "    return mfcc_scaled  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 8000/8000 [08:53<00:00, 14.98it/s]\n"
     ]
    }
   ],
   "source": [
    "# Perform the reading through all the 'train' audio files and extract the features(in this case mffc spectogram)\n",
    "features = []\n",
    "for index_audio_file in tqdm(range(0, len(audio_files_train))):\n",
    "    data = extract_features(audio_files_train, index_audio_file)\n",
    "    \n",
    "    features.append([data, train_labels[index_audio_file][1]])\n",
    "    \n",
    "# Convert into a Panda dataframe\n",
    "features_df = pd.DataFrame(features, columns=['feature','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:08<00:00, 14.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# Perform the reading through all the 'validation' audio files and extract the features\n",
    "features = []\n",
    "for index_audio_file in tqdm(range(0, len(audio_files_validation))):\n",
    "    data = extract_features(audio_files_validation, index_audio_file)\n",
    "    \n",
    "    features.append([data, validation_labels[index_audio_file][1]])\n",
    "    \n",
    "features_df_v = pd.DataFrame(features, columns=['feature','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(features_df.feature.tolist())\n",
    "y_train = np.array(features_df.label.tolist())\n",
    "\n",
    "X_validation = np.array(features_df_v.feature.tolist())\n",
    "y_validation = np.array(features_df_v.label.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(max_depth = 6, \n",
    "                              min_child_weight = 5,\n",
    "                              n_estimators=500, \n",
    "                              learning_rate=0.0995, \n",
    "                              eval_metric=\"rmse\", \n",
    "                              subsample = 0.8,\n",
    "                              colsample_bytree = 0.8,\n",
    "                              early_stopping = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, early_stopping=10,\n",
       "              eval_metric='rmse', gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints=None, learning_rate=0.0995,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=5, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=500, n_jobs=0,\n",
       "              num_parallel_tree=1, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.8,\n",
       "              tree_method=None, validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = xgb_model.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.462601\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_validation, y_predicted))\n",
    "print(\"RMSE: %f\" %(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = len([y for i, y in enumerate(y_validation) if y == 1 and y_predicted[i] == 1])\n",
    "tn = len([y for i, y in enumerate(y_validation) if y == 0 and y_predicted[i] == 0])\n",
    "fp = len([y for i, y in enumerate(y_validation) if y == 0 and y_predicted[i] == 1])\n",
    "fn = len([y for i, y in enumerate(y_validation) if y == 1 and y_predicted[i] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 78.60000%\n",
      "recall: 80.49242%\n",
      "specificity: 76.48305%\n",
      "precision: 79.29104%\n",
      "fpr: 23.51695%\n"
     ]
    }
   ],
   "source": [
    "print('accuracy: %.5f%%' % ((tp + tn) / (tp + tn + fp + fn) * 100))\n",
    "print('recall: %.5f%%' %(tp / (tp + fn) * 100))\n",
    "print('specificity: %.5f%%' %(tn / (tn + fp) * 100))\n",
    "print('precision: %.5f%%' % (tp / (tp + fp) *100))\n",
    "print('fpr: %.5f%%' %(fp / (fp + tn) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   with mask       0.78      0.76      0.77       472\n",
      "without mask       0.79      0.80      0.80       528\n",
      "\n",
      "    accuracy                           0.79      1000\n",
      "   macro avg       0.79      0.78      0.79      1000\n",
      "weighted avg       0.79      0.79      0.79      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classes = ['with mask', 'without mask']\n",
    "print(classification_report(y_validation, y_predicted, target_names = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "\n",
      "[359, 113]\n",
      "[115, 413]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = [[tn,fp],[fn,tp]]\n",
    "print(\"Confusion matrix:\\n\")\n",
    "for i in range(len(confusion_matrix)):\n",
    "    print(confusion_matrix[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test + validation:  9000\n"
     ]
    }
   ],
   "source": [
    "X_train = np.concatenate((X_train, X_validation))\n",
    "y_train = np.concatenate((y_train, y_validation))\n",
    "print(\"Test + validation: \", len(X_train))\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X_train, label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {'base_score':0.5, 'colsample_bylevel':1,\n",
    "              'colsample_bynode':1, 'colsample_bytree':1,\n",
    "              'learning_rate':0.0995, 'max_delta_step':0, 'max_depth':3,\n",
    "              'min_child_weight':1, 'n_estimators':500, 'early_stopping':10,\n",
    "              'objective':'binary:logistic', 'random_state':0, 'reg_alpha':0,\n",
    "              'reg_lambda':1, 'scale_pos_weight':1, 'subsample':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search in order to find the best params for max_depth and min_childs_weights => tune them together in order to find \n",
    "#a good tradeof between bias and variance\n",
    "gridsearch_params_md_mcw = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(3,7)\n",
    "    for min_child_weight in range(1,6)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation with max_depth=3, min_child_weight=1\n",
      "\tRMSE 0.40556666666666663 for 500 rounds\n",
      "Cross validation with max_depth=3, min_child_weight=2\n",
      "\tRMSE 0.40529 for 500 rounds\n",
      "Cross validation with max_depth=3, min_child_weight=3\n",
      "\tRMSE 0.40567833333333336 for 500 rounds\n",
      "Cross validation with max_depth=3, min_child_weight=4\n",
      "\tRMSE 0.406731 for 500 rounds\n",
      "Cross validation with max_depth=3, min_child_weight=5\n",
      "\tRMSE 0.40609433333333333 for 500 rounds\n",
      "Cross validation with max_depth=4, min_child_weight=1\n",
      "\tRMSE 0.39546466666666663 for 499 rounds\n",
      "Cross validation with max_depth=4, min_child_weight=2\n",
      "\tRMSE 0.393871 for 500 rounds\n",
      "Cross validation with max_depth=4, min_child_weight=3\n",
      "\tRMSE 0.39450999999999997 for 485 rounds\n",
      "Cross validation with max_depth=4, min_child_weight=4\n",
      "\tRMSE 0.39565233333333333 for 500 rounds\n",
      "Cross validation with max_depth=4, min_child_weight=5\n",
      "\tRMSE 0.39463699999999996 for 499 rounds\n",
      "Cross validation with max_depth=5, min_child_weight=1\n",
      "\tRMSE 0.3882046666666667 for 498 rounds\n",
      "Cross validation with max_depth=5, min_child_weight=2\n",
      "\tRMSE 0.3866716666666667 for 470 rounds\n",
      "Cross validation with max_depth=5, min_child_weight=3\n",
      "\tRMSE 0.3874123333333333 for 485 rounds\n",
      "Cross validation with max_depth=5, min_child_weight=4\n",
      "\tRMSE 0.38975099999999996 for 500 rounds\n",
      "Cross validation with max_depth=5, min_child_weight=5\n",
      "\tRMSE 0.3873256666666666 for 481 rounds\n",
      "Cross validation with max_depth=6, min_child_weight=1\n",
      "\tRMSE 0.38679733333333327 for 500 rounds\n",
      "Cross validation with max_depth=6, min_child_weight=2\n",
      "\tRMSE 0.3873873333333333 for 499 rounds\n",
      "Cross validation with max_depth=6, min_child_weight=3\n",
      "\tRMSE 0.385365 for 489 rounds\n",
      "Cross validation with max_depth=6, min_child_weight=4\n",
      "\tRMSE 0.38597666666666663 for 491 rounds\n",
      "Cross validation with max_depth=6, min_child_weight=5\n",
      "\tRMSE 0.38519233333333336 for 498 rounds\n",
      "Best params: 6, 5, : 0.38519233333333336\n"
     ]
    }
   ],
   "source": [
    "min_rmse = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "for max_depth, min_child_weight in gridsearch_params_md_mcw:\n",
    "    print(\"Cross validation with max_depth={}, min_child_weight={}\".format(max_depth, min_child_weight))\n",
    "    \n",
    "    # update parameters\n",
    "    xgb_params['max_depth'] = max_depth\n",
    "    xgb_params['min_child_weight'] = min_child_weight\n",
    "    \n",
    "    # cross validation\n",
    "    cv_results = xgb.cv(dtrain = data_dmatrix, params = xgb_params, nfold=3, \n",
    "                        num_boost_round=501, metrics=\"rmse\", as_pandas=True, seed=23)\n",
    "\n",
    "    \n",
    "    # Update best Root Mean Squared Error\n",
    "    rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {} for {} rounds\".format(rmse, boost_rounds))\n",
    "    if rmse < min_rmse:\n",
    "        min_rmse = rmse\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "        \n",
    "print(\"Best params: {}, {}, : {}\".format(best_params[0], best_params[1], min_rmse))\n",
    "\n",
    "#Update parameters:\n",
    "xgb_params['max_depth'] = best_params[0]\n",
    "xgb_params['min_child_weight'] = best_params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params_sample = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(8,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation with subsample=1.0, colsample=1.0\n",
      "\tRMSE 0.38519233333333336 for 498 rounds\n",
      "Cross validation with subsample=1.0, colsample=0.9\n",
      "\tRMSE 0.38478833333333334 for 499 rounds\n",
      "Cross validation with subsample=1.0, colsample=0.8\n",
      "\tRMSE 0.38412266666666667 for 485 rounds\n",
      "Cross validation with subsample=1.0, colsample=0.7\n",
      "\tRMSE 0.3848306666666667 for 500 rounds\n",
      "Cross validation with subsample=0.9, colsample=1.0\n",
      "\tRMSE 0.38149166666666673 for 483 rounds\n",
      "Cross validation with subsample=0.9, colsample=0.9\n",
      "\tRMSE 0.3836386666666667 for 490 rounds\n",
      "Cross validation with subsample=0.9, colsample=0.8\n",
      "\tRMSE 0.38215 for 497 rounds\n",
      "Cross validation with subsample=0.9, colsample=0.7\n",
      "\tRMSE 0.381818 for 499 rounds\n",
      "Cross validation with subsample=0.8, colsample=1.0\n",
      "\tRMSE 0.3811653333333333 for 494 rounds\n",
      "Cross validation with subsample=0.8, colsample=0.9\n",
      "\tRMSE 0.3817426666666666 for 485 rounds\n",
      "Cross validation with subsample=0.8, colsample=0.8\n",
      "\tRMSE 0.38047633333333336 for 479 rounds\n",
      "Cross validation with subsample=0.8, colsample=0.7\n",
      "\tRMSE 0.38109666666666664 for 495 rounds\n",
      "Best params: 0.8, 0.8, : 0.38047633333333336\n"
     ]
    }
   ],
   "source": [
    "min_rmse = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "for subsample, colsample in reversed(gridsearch_params_sample):\n",
    "    print(\"Cross validation with subsample={}, colsample={}\".format(subsample, colsample))\n",
    "\n",
    "    xgb_params['subsample'] = subsample\n",
    "    xgb_params['colsample_bytree'] = colsample\n",
    "\n",
    "    # cross validation\n",
    "    cv_results = xgb.cv(dtrain = data_dmatrix, params = xgb_params, nfold=3, \n",
    "                        num_boost_round=501, metrics=\"rmse\", as_pandas=True, seed=23)\n",
    "\n",
    "    # Update best Root Mean Squared Error\n",
    "    rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {} for {} rounds\".format(rmse, boost_rounds))\n",
    "    if rmse < min_rmse:\n",
    "        min_rmse = rmse\n",
    "        best_params = (subsample,colsample)\n",
    "        \n",
    "print(\"Best params: {}, {}, : {}\".format(best_params[0], best_params[1], min_rmse))\n",
    "\n",
    "#Update parameters:\n",
    "xgb_params['subsample'] = subsample\n",
    "xgb_params['colsample_bytree'] = colsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(max_depth = 6, \n",
    "                              min_child_weight = 5,\n",
    "                              n_estimators=500, \n",
    "                              learning_rate=0.0995, \n",
    "                              eval_metric=\"rmse\", \n",
    "                              subsample = 0.8,\n",
    "                              colsample_bytree = 0.8,\n",
    "                              early_stopping = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, early_stopping=10,\n",
       "              eval_metric='rmse', gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints=None, learning_rate=0.0995,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=5, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=500, n_jobs=0,\n",
       "              num_parallel_tree=1, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.8,\n",
       "              tree_method=None, validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [03:15<00:00, 15.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# Perform the reading through all the 'test' audio files and extract the features(in this case mffc spectogram)\n",
    "features = []\n",
    "for index_audio_file in tqdm(range(0, len(audio_files_test))):\n",
    "    data = extract_features(audio_files_test, index_audio_file)    \n",
    "    features.append(data)\n",
    "    \n",
    "X_test = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will save the the index of the file with the corresponding label in order to send the submission as in the sample\n",
    "submission = dict()\n",
    "for i in range(0, len(audio_files_test)):\n",
    "    dir_name, file_name = audio_files_test[i].split('./ml-fmi-23-2020/test/test')\n",
    "    index_file, extension = file_name.split(\".\")\n",
    "    submission[index_file[1:]] = y_pred[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = []\n",
    "try:\n",
    "    test = open(data_dir + '/test.txt', \"r\")\n",
    "    for line in test:\n",
    "        file, extension = line.split(\".\")\n",
    "        test_files.append(file)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {}\".format(err))\n",
    "except:\n",
    "    print(\"Unexpected error: \", sys.exc_info()[0])\n",
    "finally:\n",
    "    test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "import csv\n",
    "\n",
    "with open('submission_xgb_clean_noise_reduce_ht_fd2.csv', 'w', newline='') as fout:\n",
    "    csv_writer = csv.writer(fout)\n",
    "    csv_writer.writerow(['name','label'])\n",
    "    for i in range(0, len(test_files)):\n",
    "        csv_writer.writerow([test_files[i] + '.wav',str(submission[test_files[i]])])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
